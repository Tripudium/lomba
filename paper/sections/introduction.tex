\section{Introduction}

Modern electronic markets produce high-frequency streams of limit order book (LOB) messages: submissions, cancellations, and executions arriving at millisecond granularity. 
Trading systems increasingly need calibrated forecasts of both \emph{when} the next event will arrive and \emph{what} its attributes (marks) will be, in order to manage inventory, 
routing, and queue position. While discrete-time sequence models capture local patterns, continuous-time structure drives queue dynamics, especially around sharp changes in activity.

This paper introduces a continuous-time forecasting architecture that couples a selective state-space backbone (Mamba, \citep{gu2023mamba}) with a mixture-of-exponentials temporal point-process (TPP) head 
and hierarchical decoders for event marks (price move, size, time bucket, event type, side, and book-level proxy). 

The key ingredients are:
\begin{itemize}[leftmargin=*,itemsep=0.25em]
    \item \textbf{Continuous-time modeling}: A mixture-of-exponentials intensity yields closed-form survival and arrival probabilities over arbitrary horizons, enabling calibrated risk estimates.
    \item \textbf{Selective state-space backbone}: Mamba processes long streams efficiently and can incorporate both inter-arrival times and absolute time-of-day signals.
    \item \textbf{Hierarchical marks}: Coarse/residual binning with neighbor-aware smoothing produces sharp yet stable distributions over marks, aligning with microstructure semantics (e.g., tails beyond the spread).
    \item \textbf{Practical training recipe}: Quantile-based bin fitting on the training set, censor-aware losses, cosine warmup with AdamW, and optional soft binning for heavy-tailed features.
\end{itemize}

We focus on specifying the model, data processing, and training objectives. Experimental results and ablations will be added when broader evaluations across instruments and market regimes are complete.
